{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation (bcg)\n",
    "\n",
    "This file simplifies the process of the bcg customer segmentation. It analyzes customers on a matrix of frequency of purchase and average purchase price.\n",
    "\n",
    "We import the last three years of classics and pops ticketing transactions. Segmentation is done separately for classics and pops due to differentiations in pricing and available concerts. This will allow us to determine those who are attendees of both or just one or the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "fy_start = 16\n",
    "fy_end = 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ticket_data_import(series, fy_start=10, fy_end=19, path='data/'):\n",
    "    \"\"\"\n",
    "    This function retrieves all of the subscription files across a\\\n",
    " user determined date range and series. \n",
    "    \n",
    "    Keyword arguments:\n",
    "    series -- either 'clx' or 'pops'\n",
    "    fy_start -- earliest fiscal year in question (default 10)\n",
    "    fy_end -- last fiscal year in question (default 19)\n",
    "    path -- path to data (default 'data/')\n",
    "    \n",
    "    Returns:\n",
    "    df -- pandas dataframe consisting of ticketing data with a fiscal year added to end\n",
    "    \"\"\"\n",
    "    \n",
    "    accepted_series = ['clx', 'pops']\n",
    "    \n",
    "    if series.lower() not in accepted_series:\n",
    "        raise ValueError('series must be of accepted series types: ', \n",
    "                         accepted_series)\n",
    "    \n",
    "    dataframes = []\n",
    "    for i in range(fy_start, fy_end+1):\n",
    "        file = f\"{series.capitalize()}{i}.csv\"\n",
    "        tmp = pd.read_csv(path + file, skiprows=3)\n",
    "        tmp['fy'] = i\n",
    "        dataframes.append(tmp)\n",
    "\n",
    "    df = pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_conv(s):\n",
    "    dates = {date:pd.to_datetime(date) for date in s.unique()}\n",
    "    return s.map(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data, add a column to identify series, concatenate to one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "clx_df = ticket_data_import('clx', fy_start, fy_end)\n",
    "clx_df['series'] = 'clx'\n",
    "\n",
    "pop_df = ticket_data_import('pops', fy_start, fy_end)\n",
    "pop_df['series'] = 'pops'\n",
    "\n",
    "tix_df = pd.concat([clx_df, pop_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "tix_df['perf_dt'] = date_conv(tix_df['perf_dt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exclude Bad IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many customer IDs that should be excluded because they are corporations or internal employees or other reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ids = [\n",
    "    0,                 # Unknown IDs\n",
    "    2700674,           # Terry Dwyer\n",
    "    955085,            # PSO Comps\n",
    "    3141490,           # Symphony Shop\n",
    "    91013,             # PSO Orchestra Members\n",
    "    118401,            # PSO Prez - JF\n",
    "    91006,             # PSO Artist Comps\n",
    "    3328612,           # Development Guest\n",
    "    925728,            # Kurt Mortenson (Internal)\n",
    "    2010347,           # Goldstar\n",
    "    2437127,           # Lorraine Caukin (Internal)\n",
    "    2515897,           # Gregory Pierre Cox (internal)\n",
    "    3080718,           # Gary Good\n",
    "    91015,             # PSO Press\n",
    "    120696             # Carl St. Clair\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "tix_df = tix_df[~tix_df['summary_cust_id'].isin(bad_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "tix_df = tix_df[pd.notnull(tix_df['summary_cust_id'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Outliers\n",
    "\n",
    "There are outliers from programs and internal purchases allowing prices below 5. There are also a few entries that are greater than 500 per a single ticket which must be an entry error. Exclude those from this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "paid_constraint_min = 5\n",
    "paid_constraint_max = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "tix_df = tix_df.loc[tix_df.paid_amt > paid_constraint_min]\n",
    "tix_df = tix_df.loc[tix_df.paid_amt < paid_constraint_max]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ticket Prices dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "clx_price_df = tix_df.loc[(tix_df.series == 'clx')][['summary_cust_id', 'paid_amt']]\\\n",
    "                     .groupby(['summary_cust_id']).mean().reset_index()\n",
    "pop_price_df = tix_df.loc[(tix_df.series == 'pops')][['summary_cust_id', 'paid_amt']]\\\n",
    "                     .groupby(['summary_cust_id']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency of Concerts dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "clx_freq_df = tix_df.loc[tix_df.series == 'clx'][['summary_cust_id', 'perf_dt']]\\\n",
    "                    .drop_duplicates().groupby(['summary_cust_id']).count().reset_index()\n",
    "\n",
    "pop_freq_df = tix_df.loc[tix_df.series == 'pops'][['summary_cust_id', 'perf_dt']]\\\n",
    "                    .drop_duplicates().groupby(['summary_cust_id']).count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classics Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "clx_baselines = {\n",
    "    'avg_price': clx_price_df.paid_amt.mean(),\n",
    "    'max_price': clx_price_df.paid_amt.max(),\n",
    "    'min_price': clx_price_df.paid_amt.min(),\n",
    "    'upper_price': None,\n",
    "    'lower_price': None,\n",
    "    'avg_freq': clx_freq_df.perf_dt.mean(),\n",
    "    'max_freq': clx_freq_df.perf_dt.max(),\n",
    "    'min_freq': clx_freq_df.perf_dt.min(),\n",
    "    'upper_freq': None,\n",
    "    'lower_freq': None\n",
    "}\n",
    "\n",
    "clx_baselines['upper_price'] = np.mean([clx_baselines['avg_price'], clx_baselines['max_price']])\n",
    "clx_baselines['lower_price'] = np.mean([clx_baselines['avg_price'], clx_baselines['min_price']])\n",
    "clx_baselines['upper_freq'] = np.mean([clx_baselines['avg_freq'], clx_baselines['max_freq']])\n",
    "clx_baselines['lower_freq'] = np.mean([clx_baselines['avg_freq'], clx_baselines['min_freq']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pops Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_baselines = {\n",
    "    'avg_price': pop_price_df.paid_amt.mean(),\n",
    "    'max_price': pop_price_df.paid_amt.max(),\n",
    "    'min_price': pop_price_df.paid_amt.min(),\n",
    "    'upper_price': None,\n",
    "    'lower_price': None,\n",
    "    'avg_freq': pop_freq_df.perf_dt.mean(),\n",
    "    'max_freq': pop_freq_df.perf_dt.max(),\n",
    "    'min_freq': pop_freq_df.perf_dt.min(),\n",
    "    'upper_freq': None,\n",
    "    'lower_freq': None\n",
    "}\n",
    "\n",
    "pop_baselines['upper_price'] = np.mean([pop_baselines['avg_price'], pop_baselines['max_price']])\n",
    "pop_baselines['lower_price'] = np.mean([pop_baselines['avg_price'], pop_baselines['min_price']])\n",
    "pop_baselines['upper_freq'] = np.mean([pop_baselines['avg_freq'], pop_baselines['max_freq']])\n",
    "pop_baselines['lower_freq'] = np.mean([pop_baselines['avg_freq'], pop_baselines['min_freq']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying renew/return/new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_current = tix_df.loc[tix_df.fy == fy_end]['summary_cust_id']\\\n",
    "                     .drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_renew_range = tix_df.loc[tix_df.fy == (fy_end - 1)]['summary_cust_id']\\\n",
    "                         .drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_return_range = tix_df.loc[(tix_df.fy == (fy_start + 1)) | (tix_df.fy == fy_start)]\\\n",
    "                          ['summary_cust_id'].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_recency = {}\n",
    "\n",
    "for cust in cust_current:\n",
    "    if cust in set(cust_renew_range):\n",
    "        cust_recency.update({cust: 'renew'})\n",
    "    elif cust in set(cust_return_range):\n",
    "        cust_recency.update({cust: 'return'})\n",
    "    else:\n",
    "        cust_recency.update({cust: 'new'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(df, series, baselines, current_year=fy_end):\n",
    "    \"\"\"\n",
    "    This function takes a price df and a frequency df and determines\\\n",
    " the customer segmentation based on the baselines provided.\n",
    "    \n",
    "    Segments:\n",
    "    aficionado -- above average ticket price, above upper bound frequency.\n",
    "    high-value regular -- above upper bound ticket price, above lower bound frequency,\\\n",
    " below upper bound frequency & above avg price, above avg frequency, below lower bound\\\n",
    " frequency.\n",
    "    committed low-budget -- below average ticket price, above average frequency.\n",
    "    evolving concert-goer -- below upper bound ticket price, above lower bound frequency,\\\n",
    " below avg frequency.\n",
    "    high-value prospect -- above avg ticket price, below lower bound frequency.\n",
    "    one-timer -- below avg ticket price, below lower bound frequency.\n",
    "    \n",
    "    \n",
    "    Keyword arguments:\n",
    "    df -- dataframe consisting of 'summary_cust_id' and 'paid_amt' ('paid_amt'\\\n",
    " represents the avg price paid per ticket per customer.)\n",
    "    series -- series must either be 'clx' or 'pops'\n",
    "    baselines -- a dictionary containing: \n",
    "        {\n",
    "            avg_price: \n",
    "            max_price:\n",
    "            min_price:\n",
    "            upper_price:\n",
    "            lower_price:\n",
    "            avg_freq:\n",
    "            max_freq:\n",
    "            min_freq:\n",
    "            upper_freq:\n",
    "            lower_freq:\n",
    "        }\n",
    "    current_year -- last two digits of fiscal year in question ex. 19 for fy19 (default fy_end)\n",
    "    \n",
    "    Returns:\n",
    "    d -- dictionary taking 'summary_cust_id' as the key and a list of three items\\\n",
    " as the value. The first item is the avg ticket price for the customer, the second\\\n",
    " is the avg frequency for the customer, the third is the segment for the customer.\n",
    "    \"\"\"\n",
    "    # Check if series is clx or pops:\n",
    "    if series.lower() not in ['clx', 'pops']:\n",
    "        raise Exception(f\"series must be 'clx' or 'pops' not {series}\")\n",
    "    \n",
    "    \n",
    "    # Create dataframes for calculations\n",
    "    df = df.loc[(df['series'] == series)]\n",
    "    price_df = df[['summary_cust_id', 'paid_amt']].groupby(['summary_cust_id'])\\\n",
    "                                                  .mean().reset_index()\n",
    "    freq_df = df[['summary_cust_id', 'perf_dt']].drop_duplicates().groupby(['summary_cust_id'])\\\n",
    "                                                .count().reset_index()\n",
    "    current_cust = df.loc[df['fy'] == current_year]['summary_cust_id']\n",
    "    \n",
    "    # Initialize dataframes with unique customers from current year\n",
    "    d = {cust: [0, 0, None] for cust in current_cust}\n",
    "    \n",
    "    # Loop all customers to look up their avg ticket price and frequency\n",
    "    for k,v in d.items():\n",
    "        v[0] = price_df.loc[price_df['summary_cust_id'] == k]['paid_amt'].values[0]\n",
    "        v[1] = freq_df.loc[freq_df['summary_cust_id'] == k]['perf_dt'].values[0]\n",
    "\n",
    "        # Test to ensure that values are all greater than 0, if not there is a problem:\n",
    "        if (v[0] < 1) | (v[1] < 1):\n",
    "            raise Exception(\"Either avg tix price or frequency is less than 1, that's bad.\")\n",
    "            \n",
    "        # Fill in segments\n",
    "        if (v[0] > baselines['avg_price']) & (v[1] > baselines['upper_freq']):\n",
    "            d[k][2] = 'aficionado'\n",
    "        elif ((v[0] > baselines['upper_price']) & (v[1] < baselines['upper_freq']) & (v[1] > baselines['lower_freq'])) |\\\n",
    "            ((v[0] > baselines['avg_price']) & (v[0] < baselines['upper_price']) & (v[1] < baselines['upper_freq']) & (v[1] > baselines['avg_freq'])):\n",
    "            d[k][2] = 'high-value_regular'\n",
    "        elif (v[0] < baselines['avg_price']) & (v[1] > baselines['avg_freq']):\n",
    "            d[k][2] = 'committed_low-budget'\n",
    "        elif (v[0] < baselines['upper_price']) & (v[1] < baselines['avg_freq']) & (v[1] > baselines['lower_freq']):\n",
    "            d[k][2] = 'evolving_concert-goer'\n",
    "        elif (v[0] > baselines['avg_price']) & (v[1] < baselines['lower_freq']):\n",
    "            d[k][2] = 'high-value_prospect'\n",
    "        elif (v[0] < baselines['avg_price']) & (v[1] < baselines['lower_freq']):\n",
    "            d[k][2] = 'one-timer'\n",
    "        else:\n",
    "            raise Exception(f\"Unable to segment. Check customer {k}: {v}, {baselines}\")\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "clx_segments = segmentation(tix_df, 'clx', clx_baselines)\n",
    "pop_segments = segmentation(tix_df, 'pops', pop_baselines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27.46764705882353, 49, 'committed_low-budget']"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine into a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_segments = {int(k): {'recency': v, \n",
    "                              'clx_segment': None, \n",
    "                              'pops_segment': None} for k,v in cust_recency.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in clx_segments.items():\n",
    "    customer_segments[int(k)]['clx_segment'] = v[2]\n",
    "    \n",
    "for k,v in pop_segments.items():\n",
    "    customer_segments[int(k)]['pops_segment'] = v[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_segment_df = pd.DataFrame(customer_segments).transpose().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('customer_segments.xlsx') as writer:\n",
    "    pd.DataFrame(customer_segment_df).to_excel(writer,\n",
    "                                             engine='xlsxwriter', \n",
    "                                             index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
